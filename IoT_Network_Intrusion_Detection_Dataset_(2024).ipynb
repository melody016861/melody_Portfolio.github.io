{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOiF+6tl9sgHp5uhUjxaSB2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/melody016861/melody_Portfolio.github.io/blob/main/IoT_Network_Intrusion_Detection_Dataset_(2024).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IoT Network Intrusion Detection Dataset (2024)"
      ],
      "metadata": {
        "id": "P4xkKZay38Ai"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Title: Machine Learning for Intrusion Detection in 2024"
      ],
      "metadata": {
        "id": "MN9fn2qI54Dh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Goal:\n",
        "利用機器學習技術分析並檢測網絡入侵，以增強網絡安全措施。"
      ],
      "metadata": {
        "id": "S-CwO9Hm6SWQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Downstream Task(s):\n",
        "\n",
        "\n",
        "*   將網絡流量分類為正常或惡意。\n",
        "*   檢測各種類型的網絡攻擊。\n",
        "\n"
      ],
      "metadata": {
        "id": "Q_CnM_Pd6iOx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Where We Can Find Your Complete Codes:\n",
        "https://colab.research.google.com/drive/1vNczXjg5rIgMPhSeNWsRPPPOVIC7-rkx?hl=zh-tw#scrollTo=fb-pCR1f6lXK"
      ],
      "metadata": {
        "id": "fb-pCR1f6lXK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Introduction:\n"
      ],
      "metadata": {
        "id": "ec9HWOnd6pBG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "本報告使用的數據集來自 \"2024年機器學習網絡入侵檢測\" 研究，數據集中包含來自物聯網設備和5G網絡環境的多種網絡攻擊數據，如DDoS、SQL注入、XSS攻擊等，提供了網絡行為和攻擊模式的全面概覽，有助於開發健全的入侵檢測系統。\n",
        "\n",
        "下載網址：[IoT Network Intrusion Detection Dataset​ (BlueHood)](https://archive.ics.uci.edu/dataset/942/rt-iot2022)​"
      ],
      "metadata": {
        "id": "D0E9HfXh3_I6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "\n",
        "*   數據清洗：移除缺失或損壞的數據。\n",
        "*   特徵工程：提取如數據包長度、時間戳、源IP和目標IP等特徵。\n",
        "*   標準化：對特徵值進行標準化處理。\n",
        "\n"
      ],
      "metadata": {
        "id": "KrT4-kQM6vKS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "我們的初始模型將是一個相對簡單的模型，僅包含一個隱藏層。輸入層有94個神經元，對應於輸入數據的94個特徵。隱藏層有16個神經元，而輸出層有兩個神經元，對應於兩個類別（即攻擊模式或正常網絡流量模式）。"
      ],
      "metadata": {
        "id": "4CqQwzVY7vLG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "7hHSntS99PK3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 步驟一"
      ],
      "metadata": {
        "id": "fENgRhegtk70"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "使用 PyTorch 初始化模型，並指示其在有可用 GPU 時使用。"
      ],
      "metadata": {
        "id": "sX8SibEX8DHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "urJW8hC28LTa"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 步驟二\n",
        "下載資料集: 使用 ucimlrepo 庫從 UCI 機器學習庫中加載 RT-IoT2022 數據集"
      ],
      "metadata": {
        "id": "06AI_HYLtsPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RELSW4Bvlasf",
        "outputId": "9dfd06fc-c34d-41fc-c4eb-bd8ff04041e6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2.0.3)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "rt_iot2022 = fetch_ucirepo(id=942)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = rt_iot2022.data.features\n",
        "y = rt_iot2022.data.targets\n",
        "\n",
        "# 顯示數據集的前幾行\n",
        "print(\"Features:\")\n",
        "print(X.head())\n",
        "print(\"Targets:\")\n",
        "print(y.head())\n",
        "\n",
        "# 顯示元數據\n",
        "print(\"Metadata:\")\n",
        "print(rt_iot2022.metadata)\n",
        "\n",
        "# 顯示變量信息\n",
        "print(\"Variables:\")\n",
        "print(rt_iot2022.variables)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dI1HYzhVlSzI",
        "outputId": "409beb81-3c7c-483b-a178-83cc6c1b4378"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features:\n",
            "   id.orig_p  id.resp_p proto service  flow_duration  fwd_pkts_tot  \\\n",
            "0      38667       1883   tcp    mqtt      32.011598             9   \n",
            "1      51143       1883   tcp    mqtt      31.883584             9   \n",
            "2      44761       1883   tcp    mqtt      32.124053             9   \n",
            "3      60893       1883   tcp    mqtt      31.961063             9   \n",
            "4      51087       1883   tcp    mqtt      31.902362             9   \n",
            "\n",
            "   bwd_pkts_tot  fwd_data_pkts_tot  bwd_data_pkts_tot  fwd_pkts_per_sec  ...  \\\n",
            "0             5                  3                  3          0.281148  ...   \n",
            "1             5                  3                  3          0.282277  ...   \n",
            "2             5                  3                  3          0.280164  ...   \n",
            "3             5                  3                  3          0.281593  ...   \n",
            "4             5                  3                  3          0.282111  ...   \n",
            "\n",
            "    active.avg  active.std     idle.min     idle.max     idle.tot  \\\n",
            "0  2282414.913         0.0  29729182.96  29729182.96  29729182.96   \n",
            "1  2028306.961         0.0  29855277.06  29855277.06  29855277.06   \n",
            "2  2281903.982         0.0  29842149.02  29842149.02  29842149.02   \n",
            "3  2047288.179         0.0  29913774.97  29913774.97  29913774.97   \n",
            "4  2087656.975         0.0  29814704.90  29814704.90  29814704.90   \n",
            "\n",
            "      idle.avg  idle.std  fwd_init_window_size  bwd_init_window_size  \\\n",
            "0  29729182.96       0.0                 64240                 26847   \n",
            "1  29855277.06       0.0                 64240                 26847   \n",
            "2  29842149.02       0.0                 64240                 26847   \n",
            "3  29913774.97       0.0                 64240                 26847   \n",
            "4  29814704.90       0.0                 64240                 26847   \n",
            "\n",
            "   fwd_last_window_size  \n",
            "0                   502  \n",
            "1                   502  \n",
            "2                   502  \n",
            "3                   502  \n",
            "4                   502  \n",
            "\n",
            "[5 rows x 83 columns]\n",
            "Targets:\n",
            "    Attack_type\n",
            "0  MQTT_Publish\n",
            "1  MQTT_Publish\n",
            "2  MQTT_Publish\n",
            "3  MQTT_Publish\n",
            "4  MQTT_Publish\n",
            "Metadata:\n",
            "{'uci_id': 942, 'name': 'RT-IoT2022 ', 'repository_url': 'https://archive.ics.uci.edu/dataset/942/rt-iot2022', 'data_url': 'https://archive.ics.uci.edu/static/public/942/data.csv', 'abstract': 'The RT-IoT2022, a proprietary dataset derived from a real-time IoT infrastructure, is introduced as a comprehensive resource integrating a diverse range of IoT devices and sophisticated network attack methodologies. This dataset encompasses both normal and adversarial network behaviours, providing a general representation of real-world scenarios.\\nIncorporating data from IoT devices such as ThingSpeak-LED, Wipro-Bulb, and MQTT-Temp, as well as simulated attack scenarios involving Brute-Force SSH attacks, DDoS attacks using Hping and Slowloris, and Nmap patterns, RT-IoT2022 offers a detailed perspective on the complex nature of network traffic. The bidirectional attributes of network traffic are meticulously captured using the Zeek network monitoring tool and the Flowmeter plugin. Researchers can leverage the RT-IoT2022 dataset to advance the capabilities of Intrusion Detection Systems (IDS), fostering the development of robust and adaptive security solutions for real-time IoT networks. ', 'area': 'Engineering', 'tasks': ['Classification', 'Regression', 'Clustering'], 'characteristics': ['Tabular', 'Sequential', 'Multivariate'], 'num_instances': 123117, 'num_features': 83, 'feature_types': ['Real', 'Categorical'], 'demographics': [], 'target_col': ['Attack_type'], 'index_col': ['id'], 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2023, 'last_updated': 'Fri Mar 08 2024', 'dataset_doi': '10.24432/C5P338', 'creators': ['B. S.', 'Rohini Nagapadma'], 'intro_paper': {'title': 'Quantized autoencoder (QAE) intrusion detection system for anomaly detection in resource-constrained IoT devices using RT-IoT2022 dataset', 'authors': 'B. S. Sharmila, Rohini Nagapadma', 'published_in': 'Cybersecurity', 'year': 2023, 'url': 'https://www.semanticscholar.org/paper/753f6ede01b4acaa325e302c38f1e0c1ade74f5b', 'doi': None}, 'additional_info': {'summary': None, 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Column Details:\\nid.orig_p\\nid.resp_p\\nproto\\nservice\\nflow_duration\\nfwd_pkts_tot\\nbwd_pkts_tot\\nfwd_data_pkts_tot\\nbwd_data_pkts_tot\\nfwd_pkts_per_sec\\nbwd_pkts_per_sec\\nflow_pkts_per_sec\\ndown_up_ratio\\nfwd_header_size_tot\\nfwd_header_size_min\\nfwd_header_size_max\\nbwd_header_size_tot\\nbwd_header_size_min\\nbwd_header_size_max\\nflow_FIN_flag_count\\nflow_SYN_flag_count\\nflow_RST_flag_count\\nfwd_PSH_flag_count\\nbwd_PSH_flag_count\\nflow_ACK_flag_count\\nfwd_URG_flag_count\\nbwd_URG_flag_count\\nflow_CWR_flag_count\\nflow_ECE_flag_count\\nfwd_pkts_payload.min\\nfwd_pkts_payload.max\\nfwd_pkts_payload.tot\\nfwd_pkts_payload.avg\\nfwd_pkts_payload.std\\nbwd_pkts_payload.min\\nbwd_pkts_payload.max\\nbwd_pkts_payload.tot\\nbwd_pkts_payload.avg\\nbwd_pkts_payload.std\\nflow_pkts_payload.min\\nflow_pkts_payload.max\\nflow_pkts_payload.tot\\nflow_pkts_payload.avg\\nflow_pkts_payload.std\\nfwd_iat.min\\nfwd_iat.max\\nfwd_iat.tot\\nfwd_iat.avg\\nfwd_iat.std\\nbwd_iat.min\\nbwd_iat.max\\nbwd_iat.tot\\nbwd_iat.avg\\nbwd_iat.std\\nflow_iat.min\\nflow_iat.max\\nflow_iat.tot\\nflow_iat.avg\\nflow_iat.std\\npayload_bytes_per_second\\nfwd_subflow_pkts\\nbwd_subflow_pkts\\nfwd_subflow_bytes\\nbwd_subflow_bytes\\nfwd_bulk_bytes\\nbwd_bulk_bytes\\nfwd_bulk_packets\\nbwd_bulk_packets\\nfwd_bulk_rate\\nbwd_bulk_rate\\nactive.min\\nactive.max\\nactive.tot\\nactive.avg\\nactive.std\\nidle.min\\nidle.max\\nidle.tot\\nidle.avg\\nidle.std\\nfwd_init_window_size\\nbwd_init_window_size\\nfwd_last_window_size\\nAttack_type', 'citation': None}}\n",
            "Variables:\n",
            "                    name     role         type demographic description units  \\\n",
            "0              id.orig_p  Feature      Integer        None        None  None   \n",
            "1              id.resp_p  Feature      Integer        None        None  None   \n",
            "2                  proto  Feature  Categorical        None        None  None   \n",
            "3                service  Feature   Continuous        None        None  None   \n",
            "4          flow_duration  Feature   Continuous        None        None  None   \n",
            "..                   ...      ...          ...         ...         ...   ...   \n",
            "80  fwd_init_window_size  Feature      Integer        None        None  None   \n",
            "81  bwd_init_window_size  Feature      Integer        None        None  None   \n",
            "82  fwd_last_window_size  Feature      Integer        None        None  None   \n",
            "83           Attack_type   Target  Categorical        None        None  None   \n",
            "84                    id       ID      Integer        None        None  None   \n",
            "\n",
            "   missing_values  \n",
            "0              no  \n",
            "1              no  \n",
            "2              no  \n",
            "3              no  \n",
            "4              no  \n",
            "..            ...  \n",
            "80             no  \n",
            "81             no  \n",
            "82             no  \n",
            "83             no  \n",
            "84             no  \n",
            "\n",
            "[85 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 步驟三\n",
        "將下載的數據集轉為csv檔。"
      ],
      "metadata": {
        "id": "q1Ypby0otxTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "import pandas as pd\n",
        "\n",
        "# 獲取數據集\n",
        "rt_iot2022 = fetch_ucirepo(id=942)\n",
        "\n",
        "# 提取特徵和目標數據\n",
        "X = rt_iot2022.data.features\n",
        "y = rt_iot2022.data.targets\n",
        "\n",
        "# 合併特徵和目標數據到一個 DataFrame 中\n",
        "df = X.copy()\n",
        "df['Attack_type'] = y\n",
        "\n",
        "# 設置 CSV 文件保存路徑\n",
        "csv_file_path = r'C:\\Users\\Melody\\OneDrive\\文件\\大四下\\網路安全\\FinalProject\\RT_IOT2022.csv'\n",
        "\n",
        "# 保存為 CSV 文件\n",
        "df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "# 確認文件已保存\n",
        "import os\n",
        "if os.path.exists(csv_file_path):\n",
        "    print(f\"CSV 文件已成功保存至: {os.path.abspath(csv_file_path)}\")\n",
        "else:\n",
        "    print(\"文件保存失敗\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpr4cmLgmylH",
        "outputId": "abf2b449-797d-4562-e904-c58bc5041dc1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV 文件已成功保存至: /content/C:\\Users\\Melody\\OneDrive\\文件\\大四下\\網路安全\\FinalProject\\RT_IOT2022.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 數據預處理\n",
        "在進行數據分析之前，我們需要對數據進行適當的預處理。這包括確保標籤數據的正確性、進行編碼、數據標準化以及將數據集拆分為訓練集和測試集。\n",
        "\n",
        "具體步驟如下：\n",
        "1. 轉換非數值型特徵為數值型：使用 one-hot 編碼將類別特徵轉換為數值特徵。\n",
        "2. 數據標準化：確保所有數據都是數值型並進行標準化處理。\n",
        "3. 拆分數據集：將數據集拆分為訓練集和測試集，其中訓練集用於訓練模型，測試集用於評估模型性能。"
      ],
      "metadata": {
        "id": "gDwOmhcap9Aj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 載入數據集\n",
        "df = pd.read_csv(r'C:\\Users\\Melody\\OneDrive\\文件\\大四下\\網路安全\\FinalProject\\RT_IOT2022.csv')\n",
        "\n",
        "# 將數據集拆分為訓練集和測試集\n",
        "# 打亂數據集\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "train_size = int(0.8 * len(df))\n",
        "train_df = df.iloc[:train_size, :].reset_index(drop=True)\n",
        "test_df = df.iloc[train_size:, :].reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "qwORxeaAoxpt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 加載數據集\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "rt_iot2022 = fetch_ucirepo(id=942)\n",
        "X = rt_iot2022.data.features\n",
        "y = rt_iot2022.data.targets\n",
        "\n",
        "# 確保 y 只包含目標變量，並轉換為 Series\n",
        "y = y.squeeze()  # 如果 y 是 DataFrame，這會將其轉換為 Series\n",
        "\n",
        "# 檢查標籤數據的唯一值\n",
        "print(\"標籤數據的唯一值:\")\n",
        "print(y.unique())\n",
        "\n",
        "# 將標籤進行編碼\n",
        "unique_labels = y.unique()\n",
        "label_mapping = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "y = y.map(label_mapping)\n",
        "\n",
        "# 檢查編碼後的標籤數據唯一值範圍\n",
        "print(\"編碼後的標籤數據的唯一值:\")\n",
        "print(y.unique())\n",
        "\n",
        "# 將非數值型特徵轉換為數值型\n",
        "X = pd.get_dummies(X)\n",
        "\n",
        "# 將數據集拆分為訓練集和測試集\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 數據標準化\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 合併特徵和標籤數據到 DataFrame 中\n",
        "train_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
        "train_df['Attack_type'] = y_train.values\n",
        "test_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
        "test_df['Attack_type'] = y_test.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPUeXxrop3H7",
        "outputId": "57bb5b19-3c95-454f-880d-60a984294a2b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "標籤數據的唯一值:\n",
            "['MQTT_Publish' 'Thing_Speak' 'Wipro_bulb' 'ARP_poisioning'\n",
            " 'DDOS_Slowloris' 'DOS_SYN_Hping' 'Metasploit_Brute_Force_SSH'\n",
            " 'NMAP_FIN_SCAN' 'NMAP_OS_DETECTION' 'NMAP_TCP_scan' 'NMAP_UDP_SCAN'\n",
            " 'NMAP_XMAS_TREE_SCAN']\n",
            "編碼後的標籤數據的唯一值:\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "標籤數據的唯一值顯示已成功編碼，且範圍在 [0, 11] 之間，這代表標籤數據應該是正確的。接下來，需要確保模型的輸出層大小與標籤數據的類別數一致，即模型的輸出層應該有 12 個神經元。"
      ],
      "metadata": {
        "id": "-mbZfw66sySg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 自定義數據集\n",
        "\n",
        "在這部分，我定義了一個自定義的數據集類，以便於使用 PyTorch 進行數據加載和處理。這個自定義數據集類接受一個 pandas DataFrame 作為輸入，並將其存儲為類的屬性。該類包含兩個方法：\n",
        "\n",
        "1. __len__ 方法：返回數據集中的樣本總數，即 DataFrame 的行數。\n",
        "2. __getitem__ 方法：根據給定的索引（idx）檢索數據集中的特定樣本，並返回該索引處的特徵和標籤。\n",
        "\n",
        "加載數據集：\n",
        "\n",
        "將訓練數據集和測試數據集加載到自定義數據集類中。"
      ],
      "metadata": {
        "id": "K-sYMDTC8mYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.dataframe = dataframe\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        features = torch.tensor(self.dataframe.drop('Attack_type', axis=1).iloc[idx, :].values, dtype=torch.float32)\n",
        "        target = torch.tensor(int(self.dataframe.loc[idx, 'Attack_type']), dtype=torch.long)  # 確保標籤是 long 型\n",
        "        return features, target\n",
        "\n",
        "# 將數據加載到自定義數據集中\n",
        "train_dataset = CustomDataset(train_df)\n",
        "test_dataset = CustomDataset(test_df)\n",
        "\n",
        "batch_size = 100\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "aK8l8ItL89CX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "接下來，將這些自定義數據集（訓練集和測試集）加載到 PyTorch 的 DataLoader 對象中。DataLoader 是一個實用工具，提供了一種高效的方式來加載和遍歷數據集。我指定了批量大小為 100，這代表模型會在每次權重更新前，先在一個子集（本例中為 100 個樣本）上進行訓練。這樣，模型在每個訓練周期內會多次更新權重。\n",
        "\n",
        "使用 DataLoader：\n",
        "\n",
        "1. 將自定義數據集加載到 PyTorch 的 DataLoader 中，指定批量大小為 100。\n",
        "2. 訓練數據集使用 shuffle=True 參數，以確保數據在每個訓練周期內是隨機的。\n",
        "3. 測試數據集使用 shuffle=False 參數，以確保數據順序一致。"
      ],
      "metadata": {
        "id": "dxNpitUU8-Kk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "aeHWlGWq9Hmz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 模型定義\n",
        "\n",
        "我定義了一個神經網絡模型，該模型繼承自 nn.Module 類。這個類定義了神經網絡的結構，包括每層的神經元數量和激活函數。在這個模型中，我使用了 ReLU 激活函數和線性激活函數。"
      ],
      "metadata": {
        "id": "9ZIaNVxk9SY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.l1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.l3 = nn.Linear(hidden_size, num_classes)  # 確保輸出層大小與類別數一致\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.l3(out)\n",
        "        return out\n",
        "\n",
        "input_size = X_train_scaled.shape[1] # 輸入層的神經元數量，對應於輸入特徵數\n",
        "hidden_size = 64 # 隱藏層的神經元數量\n",
        "num_classes = 12  # 輸出層的神經元數量應與標籤類別數一致\n",
        "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss() # 使用交叉熵損失函數\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # 使用 Adam 優化器，學習率為 0.001"
      ],
      "metadata": {
        "id": "7vxLhxgL9bDG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "在這個模型中：\n",
        "\n",
        "\n",
        "*   __init__ 方法定義了網絡的各層：\n",
        "  *   第一層是從輸入層到隱藏層，包含 input_size 個輸入神經元和 hidden_size 個隱藏神經元。\n",
        "  *   第二層是隱藏層，包含 hidden_size 個隱藏神經元。\n",
        "  *   第三層是從隱藏層到輸出層，包含 num_classes 個輸出神經元。\n",
        "*   forward 方法定義了前向傳播過程，即數據如何通過網絡進行計算。"
      ],
      "metadata": {
        "id": "wDwRS17xwH8d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 訓練循環\n",
        "\n",
        "接著進行訓練循環。訓練循環遍歷指定的訓練周期數，內部循環遍歷訓練 DataLoader 中的批次。如果有可用的 GPU 設備，特徵和標籤也會移動到 GPU 上。神經網絡使用輸入特徵進行前向傳播，並計算損失。在此階段，優化器的梯度使用 optimizer.zero_grad() 歸零，以防止累積自前一次迭代的梯度。接著完成反向傳播，計算損失相對於模型參數的梯度。然後，優化器根據計算出的梯度更新參數。"
      ],
      "metadata": {
        "id": "1Ej_Iep_9cbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_total_steps = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (features, labels) in enumerate(train_loader):\n",
        "        features = features.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # 前向傳播\n",
        "        outputs = model(features)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # 反向傳播\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 5 == 0:\n",
        "            print(f'Epoch {epoch+1} / {num_epochs} | Step {i+1} / {n_total_steps} | Loss = {loss.item():.4f}')"
      ],
      "metadata": {
        "id": "YEJy-m0M9ec1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fe13515-9a2d-413f-9eca-7f7b02a40d17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 10 | Step 5 / 985 | Loss = 2.2569\n",
            "Epoch 1 / 10 | Step 10 / 985 | Loss = 2.1255\n",
            "Epoch 1 / 10 | Step 15 / 985 | Loss = 1.9591\n",
            "Epoch 1 / 10 | Step 20 / 985 | Loss = 1.7228\n",
            "Epoch 1 / 10 | Step 25 / 985 | Loss = 1.4896\n",
            "Epoch 1 / 10 | Step 30 / 985 | Loss = 1.0829\n",
            "Epoch 1 / 10 | Step 35 / 985 | Loss = 1.0948\n",
            "Epoch 1 / 10 | Step 40 / 985 | Loss = 0.5109\n",
            "Epoch 1 / 10 | Step 45 / 985 | Loss = 0.2769\n",
            "Epoch 1 / 10 | Step 50 / 985 | Loss = 0.4098\n",
            "Epoch 1 / 10 | Step 55 / 985 | Loss = 0.2780\n",
            "Epoch 1 / 10 | Step 60 / 985 | Loss = 0.3197\n",
            "Epoch 1 / 10 | Step 65 / 985 | Loss = 0.1986\n",
            "Epoch 1 / 10 | Step 70 / 985 | Loss = 0.1785\n",
            "Epoch 1 / 10 | Step 75 / 985 | Loss = 0.2465\n",
            "Epoch 1 / 10 | Step 80 / 985 | Loss = 0.2407\n",
            "Epoch 1 / 10 | Step 85 / 985 | Loss = 0.2439\n",
            "Epoch 1 / 10 | Step 90 / 985 | Loss = 0.1642\n",
            "Epoch 1 / 10 | Step 95 / 985 | Loss = 0.2006\n",
            "Epoch 1 / 10 | Step 100 / 985 | Loss = 0.2048\n",
            "Epoch 1 / 10 | Step 105 / 985 | Loss = 0.2148\n",
            "Epoch 1 / 10 | Step 110 / 985 | Loss = 0.2208\n",
            "Epoch 1 / 10 | Step 115 / 985 | Loss = 0.1561\n",
            "Epoch 1 / 10 | Step 120 / 985 | Loss = 0.1435\n",
            "Epoch 1 / 10 | Step 125 / 985 | Loss = 0.1178\n",
            "Epoch 1 / 10 | Step 130 / 985 | Loss = 0.2026\n",
            "Epoch 1 / 10 | Step 135 / 985 | Loss = 0.1295\n",
            "Epoch 1 / 10 | Step 140 / 985 | Loss = 0.2021\n",
            "Epoch 1 / 10 | Step 145 / 985 | Loss = 0.0592\n",
            "Epoch 1 / 10 | Step 150 / 985 | Loss = 0.1734\n",
            "Epoch 1 / 10 | Step 155 / 985 | Loss = 0.1042\n",
            "Epoch 1 / 10 | Step 160 / 985 | Loss = 0.1385\n",
            "Epoch 1 / 10 | Step 165 / 985 | Loss = 0.0828\n",
            "Epoch 1 / 10 | Step 170 / 985 | Loss = 0.0723\n",
            "Epoch 1 / 10 | Step 175 / 985 | Loss = 0.1179\n",
            "Epoch 1 / 10 | Step 180 / 985 | Loss = 0.0892\n",
            "Epoch 1 / 10 | Step 185 / 985 | Loss = 0.1572\n",
            "Epoch 1 / 10 | Step 190 / 985 | Loss = 0.1205\n",
            "Epoch 1 / 10 | Step 195 / 985 | Loss = 0.0475\n",
            "Epoch 1 / 10 | Step 200 / 985 | Loss = 0.0736\n",
            "Epoch 1 / 10 | Step 205 / 985 | Loss = 0.1095\n",
            "Epoch 1 / 10 | Step 210 / 985 | Loss = 0.1377\n",
            "Epoch 1 / 10 | Step 215 / 985 | Loss = 0.1366\n",
            "Epoch 1 / 10 | Step 220 / 985 | Loss = 0.1315\n",
            "Epoch 1 / 10 | Step 225 / 985 | Loss = 0.0951\n",
            "Epoch 1 / 10 | Step 230 / 985 | Loss = 0.1509\n",
            "Epoch 1 / 10 | Step 235 / 985 | Loss = 0.1072\n",
            "Epoch 1 / 10 | Step 240 / 985 | Loss = 0.0789\n",
            "Epoch 1 / 10 | Step 245 / 985 | Loss = 0.1830\n",
            "Epoch 1 / 10 | Step 250 / 985 | Loss = 0.0416\n",
            "Epoch 1 / 10 | Step 255 / 985 | Loss = 0.1242\n",
            "Epoch 1 / 10 | Step 260 / 985 | Loss = 0.0976\n",
            "Epoch 1 / 10 | Step 265 / 985 | Loss = 0.0688\n",
            "Epoch 1 / 10 | Step 270 / 985 | Loss = 0.1009\n",
            "Epoch 1 / 10 | Step 275 / 985 | Loss = 0.0389\n",
            "Epoch 1 / 10 | Step 280 / 985 | Loss = 0.0754\n",
            "Epoch 1 / 10 | Step 285 / 985 | Loss = 0.0680\n",
            "Epoch 1 / 10 | Step 290 / 985 | Loss = 0.0931\n",
            "Epoch 1 / 10 | Step 295 / 985 | Loss = 0.0671\n",
            "Epoch 1 / 10 | Step 300 / 985 | Loss = 0.0865\n",
            "Epoch 1 / 10 | Step 305 / 985 | Loss = 0.1710\n",
            "Epoch 1 / 10 | Step 310 / 985 | Loss = 0.0453\n",
            "Epoch 1 / 10 | Step 315 / 985 | Loss = 0.0811\n",
            "Epoch 1 / 10 | Step 320 / 985 | Loss = 0.0600\n",
            "Epoch 1 / 10 | Step 325 / 985 | Loss = 0.0626\n",
            "Epoch 1 / 10 | Step 330 / 985 | Loss = 0.0373\n",
            "Epoch 1 / 10 | Step 335 / 985 | Loss = 0.0372\n",
            "Epoch 1 / 10 | Step 340 / 985 | Loss = 0.1696\n",
            "Epoch 1 / 10 | Step 345 / 985 | Loss = 0.0991\n",
            "Epoch 1 / 10 | Step 350 / 985 | Loss = 0.0257\n",
            "Epoch 1 / 10 | Step 355 / 985 | Loss = 0.0573\n",
            "Epoch 1 / 10 | Step 360 / 985 | Loss = 0.0617\n",
            "Epoch 1 / 10 | Step 365 / 985 | Loss = 0.0897\n",
            "Epoch 1 / 10 | Step 370 / 985 | Loss = 0.0345\n",
            "Epoch 1 / 10 | Step 375 / 985 | Loss = 0.0310\n",
            "Epoch 1 / 10 | Step 380 / 985 | Loss = 0.0230\n",
            "Epoch 1 / 10 | Step 385 / 985 | Loss = 0.0741\n",
            "Epoch 1 / 10 | Step 390 / 985 | Loss = 0.0343\n",
            "Epoch 1 / 10 | Step 395 / 985 | Loss = 0.1734\n",
            "Epoch 1 / 10 | Step 400 / 985 | Loss = 0.0730\n",
            "Epoch 1 / 10 | Step 405 / 985 | Loss = 0.0443\n",
            "Epoch 1 / 10 | Step 410 / 985 | Loss = 0.0645\n",
            "Epoch 1 / 10 | Step 415 / 985 | Loss = 0.1387\n",
            "Epoch 1 / 10 | Step 420 / 985 | Loss = 0.2594\n",
            "Epoch 1 / 10 | Step 425 / 985 | Loss = 0.0487\n",
            "Epoch 1 / 10 | Step 430 / 985 | Loss = 0.0845\n",
            "Epoch 1 / 10 | Step 435 / 985 | Loss = 0.0694\n",
            "Epoch 1 / 10 | Step 440 / 985 | Loss = 0.0657\n",
            "Epoch 1 / 10 | Step 445 / 985 | Loss = 0.0344\n",
            "Epoch 1 / 10 | Step 450 / 985 | Loss = 0.0950\n",
            "Epoch 1 / 10 | Step 455 / 985 | Loss = 0.0724\n",
            "Epoch 1 / 10 | Step 460 / 985 | Loss = 0.0619\n",
            "Epoch 1 / 10 | Step 465 / 985 | Loss = 0.0213\n",
            "Epoch 1 / 10 | Step 470 / 985 | Loss = 0.0494\n",
            "Epoch 1 / 10 | Step 475 / 985 | Loss = 0.0367\n",
            "Epoch 1 / 10 | Step 480 / 985 | Loss = 0.0485\n",
            "Epoch 1 / 10 | Step 485 / 985 | Loss = 0.0300\n",
            "Epoch 1 / 10 | Step 490 / 985 | Loss = 0.0460\n",
            "Epoch 1 / 10 | Step 495 / 985 | Loss = 0.1048\n",
            "Epoch 1 / 10 | Step 500 / 985 | Loss = 0.0648\n",
            "Epoch 1 / 10 | Step 505 / 985 | Loss = 0.0681\n",
            "Epoch 1 / 10 | Step 510 / 985 | Loss = 0.0581\n",
            "Epoch 1 / 10 | Step 515 / 985 | Loss = 0.0655\n",
            "Epoch 1 / 10 | Step 520 / 985 | Loss = 0.0262\n",
            "Epoch 1 / 10 | Step 525 / 985 | Loss = 0.0410\n",
            "Epoch 1 / 10 | Step 530 / 985 | Loss = 0.0413\n",
            "Epoch 1 / 10 | Step 535 / 985 | Loss = 0.0332\n",
            "Epoch 1 / 10 | Step 540 / 985 | Loss = 0.0800\n",
            "Epoch 1 / 10 | Step 545 / 985 | Loss = 0.0225\n",
            "Epoch 1 / 10 | Step 550 / 985 | Loss = 0.0718\n",
            "Epoch 1 / 10 | Step 555 / 985 | Loss = 0.0533\n",
            "Epoch 1 / 10 | Step 560 / 985 | Loss = 0.0506\n",
            "Epoch 1 / 10 | Step 565 / 985 | Loss = 0.0087\n",
            "Epoch 1 / 10 | Step 570 / 985 | Loss = 0.1525\n",
            "Epoch 1 / 10 | Step 575 / 985 | Loss = 0.0264\n",
            "Epoch 1 / 10 | Step 580 / 985 | Loss = 0.0844\n",
            "Epoch 1 / 10 | Step 585 / 985 | Loss = 0.0125\n",
            "Epoch 1 / 10 | Step 590 / 985 | Loss = 0.0243\n",
            "Epoch 1 / 10 | Step 595 / 985 | Loss = 0.0390\n",
            "Epoch 1 / 10 | Step 600 / 985 | Loss = 0.0207\n",
            "Epoch 1 / 10 | Step 605 / 985 | Loss = 0.0355\n",
            "Epoch 1 / 10 | Step 610 / 985 | Loss = 0.0194\n",
            "Epoch 1 / 10 | Step 615 / 985 | Loss = 0.0291\n",
            "Epoch 1 / 10 | Step 620 / 985 | Loss = 0.1056\n",
            "Epoch 1 / 10 | Step 625 / 985 | Loss = 0.0450\n",
            "Epoch 1 / 10 | Step 630 / 985 | Loss = 0.0230\n",
            "Epoch 1 / 10 | Step 635 / 985 | Loss = 0.0775\n",
            "Epoch 1 / 10 | Step 640 / 985 | Loss = 0.0247\n",
            "Epoch 1 / 10 | Step 645 / 985 | Loss = 0.0221\n",
            "Epoch 1 / 10 | Step 650 / 985 | Loss = 0.0389\n",
            "Epoch 1 / 10 | Step 655 / 985 | Loss = 0.0276\n",
            "Epoch 1 / 10 | Step 660 / 985 | Loss = 0.0621\n",
            "Epoch 1 / 10 | Step 665 / 985 | Loss = 0.0665\n",
            "Epoch 1 / 10 | Step 670 / 985 | Loss = 0.0473\n",
            "Epoch 1 / 10 | Step 675 / 985 | Loss = 0.0275\n",
            "Epoch 1 / 10 | Step 680 / 985 | Loss = 0.0331\n",
            "Epoch 1 / 10 | Step 685 / 985 | Loss = 0.0613\n",
            "Epoch 1 / 10 | Step 690 / 985 | Loss = 0.1032\n",
            "Epoch 1 / 10 | Step 695 / 985 | Loss = 0.0550\n",
            "Epoch 1 / 10 | Step 700 / 985 | Loss = 0.0581\n",
            "Epoch 1 / 10 | Step 705 / 985 | Loss = 0.0098\n",
            "Epoch 1 / 10 | Step 710 / 985 | Loss = 0.0253\n",
            "Epoch 1 / 10 | Step 715 / 985 | Loss = 0.0359\n",
            "Epoch 1 / 10 | Step 720 / 985 | Loss = 0.0243\n",
            "Epoch 1 / 10 | Step 725 / 985 | Loss = 0.0066\n",
            "Epoch 1 / 10 | Step 730 / 985 | Loss = 0.0755\n",
            "Epoch 1 / 10 | Step 735 / 985 | Loss = 0.0297\n",
            "Epoch 1 / 10 | Step 740 / 985 | Loss = 0.0137\n",
            "Epoch 1 / 10 | Step 745 / 985 | Loss = 0.0137\n",
            "Epoch 1 / 10 | Step 750 / 985 | Loss = 0.0303\n",
            "Epoch 1 / 10 | Step 755 / 985 | Loss = 0.0505\n",
            "Epoch 1 / 10 | Step 760 / 985 | Loss = 0.0397\n",
            "Epoch 1 / 10 | Step 765 / 985 | Loss = 0.0672\n",
            "Epoch 1 / 10 | Step 770 / 985 | Loss = 0.0281\n",
            "Epoch 1 / 10 | Step 775 / 985 | Loss = 0.0303\n",
            "Epoch 1 / 10 | Step 780 / 985 | Loss = 0.0113\n",
            "Epoch 1 / 10 | Step 785 / 985 | Loss = 0.0420\n",
            "Epoch 1 / 10 | Step 790 / 985 | Loss = 0.0555\n",
            "Epoch 1 / 10 | Step 795 / 985 | Loss = 0.0744\n",
            "Epoch 1 / 10 | Step 800 / 985 | Loss = 0.0248\n",
            "Epoch 1 / 10 | Step 805 / 985 | Loss = 0.0310\n",
            "Epoch 1 / 10 | Step 810 / 985 | Loss = 0.0133\n",
            "Epoch 1 / 10 | Step 815 / 985 | Loss = 0.0623\n",
            "Epoch 1 / 10 | Step 820 / 985 | Loss = 0.0261\n",
            "Epoch 1 / 10 | Step 825 / 985 | Loss = 0.0945\n",
            "Epoch 1 / 10 | Step 830 / 985 | Loss = 0.0204\n",
            "Epoch 1 / 10 | Step 835 / 985 | Loss = 0.0507\n",
            "Epoch 1 / 10 | Step 840 / 985 | Loss = 0.0384\n",
            "Epoch 1 / 10 | Step 845 / 985 | Loss = 0.0345\n",
            "Epoch 1 / 10 | Step 850 / 985 | Loss = 0.0525\n",
            "Epoch 1 / 10 | Step 855 / 985 | Loss = 0.0132\n",
            "Epoch 1 / 10 | Step 860 / 985 | Loss = 0.0501\n",
            "Epoch 1 / 10 | Step 865 / 985 | Loss = 0.0268\n",
            "Epoch 1 / 10 | Step 870 / 985 | Loss = 0.0385\n",
            "Epoch 1 / 10 | Step 875 / 985 | Loss = 0.0153\n",
            "Epoch 1 / 10 | Step 880 / 985 | Loss = 0.0911\n",
            "Epoch 1 / 10 | Step 885 / 985 | Loss = 0.0099\n",
            "Epoch 1 / 10 | Step 890 / 985 | Loss = 0.0580\n",
            "Epoch 1 / 10 | Step 895 / 985 | Loss = 0.1189\n",
            "Epoch 1 / 10 | Step 900 / 985 | Loss = 0.0773\n",
            "Epoch 1 / 10 | Step 905 / 985 | Loss = 0.0393\n",
            "Epoch 1 / 10 | Step 910 / 985 | Loss = 0.0157\n",
            "Epoch 1 / 10 | Step 915 / 985 | Loss = 0.0135\n",
            "Epoch 1 / 10 | Step 920 / 985 | Loss = 0.0080\n",
            "Epoch 1 / 10 | Step 925 / 985 | Loss = 0.0067\n",
            "Epoch 1 / 10 | Step 930 / 985 | Loss = 0.0389\n",
            "Epoch 1 / 10 | Step 935 / 985 | Loss = 0.0194\n",
            "Epoch 1 / 10 | Step 940 / 985 | Loss = 0.0139\n",
            "Epoch 1 / 10 | Step 945 / 985 | Loss = 0.0860\n",
            "Epoch 1 / 10 | Step 950 / 985 | Loss = 0.0174\n",
            "Epoch 1 / 10 | Step 955 / 985 | Loss = 0.0876\n",
            "Epoch 1 / 10 | Step 960 / 985 | Loss = 0.4495\n",
            "Epoch 1 / 10 | Step 965 / 985 | Loss = 0.0255\n",
            "Epoch 1 / 10 | Step 970 / 985 | Loss = 0.0181\n",
            "Epoch 1 / 10 | Step 975 / 985 | Loss = 0.0343\n",
            "Epoch 1 / 10 | Step 980 / 985 | Loss = 0.0346\n",
            "Epoch 1 / 10 | Step 985 / 985 | Loss = 0.1744\n",
            "Epoch 2 / 10 | Step 5 / 985 | Loss = 0.0571\n",
            "Epoch 2 / 10 | Step 10 / 985 | Loss = 0.0443\n",
            "Epoch 2 / 10 | Step 15 / 985 | Loss = 0.0092\n",
            "Epoch 2 / 10 | Step 20 / 985 | Loss = 0.0193\n",
            "Epoch 2 / 10 | Step 25 / 985 | Loss = 0.0515\n",
            "Epoch 2 / 10 | Step 30 / 985 | Loss = 0.0135\n",
            "Epoch 2 / 10 | Step 35 / 985 | Loss = 0.0535\n",
            "Epoch 2 / 10 | Step 40 / 985 | Loss = 0.4972\n",
            "Epoch 2 / 10 | Step 45 / 985 | Loss = 0.1455\n",
            "Epoch 2 / 10 | Step 50 / 985 | Loss = 0.0551\n",
            "Epoch 2 / 10 | Step 55 / 985 | Loss = 0.0164\n",
            "Epoch 2 / 10 | Step 60 / 985 | Loss = 0.0386\n",
            "Epoch 2 / 10 | Step 65 / 985 | Loss = 0.0537\n",
            "Epoch 2 / 10 | Step 70 / 985 | Loss = 0.0699\n",
            "Epoch 2 / 10 | Step 75 / 985 | Loss = 0.2175\n",
            "Epoch 2 / 10 | Step 80 / 985 | Loss = 0.0389\n",
            "Epoch 2 / 10 | Step 85 / 985 | Loss = 0.0196\n",
            "Epoch 2 / 10 | Step 90 / 985 | Loss = 0.0266\n",
            "Epoch 2 / 10 | Step 95 / 985 | Loss = 0.0144\n",
            "Epoch 2 / 10 | Step 100 / 985 | Loss = 0.0387\n",
            "Epoch 2 / 10 | Step 105 / 985 | Loss = 0.0554\n",
            "Epoch 2 / 10 | Step 110 / 985 | Loss = 0.0332\n",
            "Epoch 2 / 10 | Step 115 / 985 | Loss = 0.0345\n",
            "Epoch 2 / 10 | Step 120 / 985 | Loss = 0.0076\n",
            "Epoch 2 / 10 | Step 125 / 985 | Loss = 0.0485\n",
            "Epoch 2 / 10 | Step 130 / 985 | Loss = 0.0342\n",
            "Epoch 2 / 10 | Step 135 / 985 | Loss = 0.0165\n",
            "Epoch 2 / 10 | Step 140 / 985 | Loss = 0.0062\n",
            "Epoch 2 / 10 | Step 145 / 985 | Loss = 0.0499\n",
            "Epoch 2 / 10 | Step 150 / 985 | Loss = 0.0590\n",
            "Epoch 2 / 10 | Step 155 / 985 | Loss = 0.0124\n",
            "Epoch 2 / 10 | Step 160 / 985 | Loss = 0.0185\n",
            "Epoch 2 / 10 | Step 165 / 985 | Loss = 0.0339\n",
            "Epoch 2 / 10 | Step 170 / 985 | Loss = 0.0519\n",
            "Epoch 2 / 10 | Step 175 / 985 | Loss = 0.0525\n",
            "Epoch 2 / 10 | Step 180 / 985 | Loss = 0.0141\n",
            "Epoch 2 / 10 | Step 185 / 985 | Loss = 0.0096\n",
            "Epoch 2 / 10 | Step 190 / 985 | Loss = 0.0161\n",
            "Epoch 2 / 10 | Step 195 / 985 | Loss = 0.0149\n",
            "Epoch 2 / 10 | Step 200 / 985 | Loss = 0.1061\n",
            "Epoch 2 / 10 | Step 205 / 985 | Loss = 0.0467\n",
            "Epoch 2 / 10 | Step 210 / 985 | Loss = 0.0793\n",
            "Epoch 2 / 10 | Step 215 / 985 | Loss = 0.0069\n",
            "Epoch 2 / 10 | Step 220 / 985 | Loss = 0.0161\n",
            "Epoch 2 / 10 | Step 225 / 985 | Loss = 0.0335\n",
            "Epoch 2 / 10 | Step 230 / 985 | Loss = 0.0608\n",
            "Epoch 2 / 10 | Step 235 / 985 | Loss = 0.0554\n",
            "Epoch 2 / 10 | Step 240 / 985 | Loss = 0.0092\n",
            "Epoch 2 / 10 | Step 245 / 985 | Loss = 0.0309\n",
            "Epoch 2 / 10 | Step 250 / 985 | Loss = 0.0244\n",
            "Epoch 2 / 10 | Step 255 / 985 | Loss = 0.0254\n",
            "Epoch 2 / 10 | Step 260 / 985 | Loss = 0.1239\n",
            "Epoch 2 / 10 | Step 265 / 985 | Loss = 0.0817\n",
            "Epoch 2 / 10 | Step 270 / 985 | Loss = 0.0329\n",
            "Epoch 2 / 10 | Step 275 / 985 | Loss = 0.0574\n",
            "Epoch 2 / 10 | Step 280 / 985 | Loss = 0.0206\n",
            "Epoch 2 / 10 | Step 285 / 985 | Loss = 0.0304\n",
            "Epoch 2 / 10 | Step 290 / 985 | Loss = 0.0248\n",
            "Epoch 2 / 10 | Step 295 / 985 | Loss = 0.0508\n",
            "Epoch 2 / 10 | Step 300 / 985 | Loss = 0.1656\n",
            "Epoch 2 / 10 | Step 305 / 985 | Loss = 0.0220\n",
            "Epoch 2 / 10 | Step 310 / 985 | Loss = 0.0225\n",
            "Epoch 2 / 10 | Step 315 / 985 | Loss = 0.0741\n",
            "Epoch 2 / 10 | Step 320 / 985 | Loss = 0.0398\n",
            "Epoch 2 / 10 | Step 325 / 985 | Loss = 0.0279\n",
            "Epoch 2 / 10 | Step 330 / 985 | Loss = 0.0201\n",
            "Epoch 2 / 10 | Step 340 / 985 | Loss = 0.0145\n",
            "Epoch 2 / 10 | Step 345 / 985 | Loss = 0.0044\n",
            "Epoch 2 / 10 | Step 350 / 985 | Loss = 0.0265\n",
            "Epoch 2 / 10 | Step 355 / 985 | Loss = 0.0533\n",
            "Epoch 2 / 10 | Step 360 / 985 | Loss = 0.0402\n",
            "Epoch 2 / 10 | Step 365 / 985 | Loss = 0.0523\n",
            "Epoch 2 / 10 | Step 370 / 985 | Loss = 0.0337\n",
            "Epoch 2 / 10 | Step 375 / 985 | Loss = 0.0236\n",
            "Epoch 2 / 10 | Step 380 / 985 | Loss = 0.0303\n",
            "Epoch 2 / 10 | Step 385 / 985 | Loss = 0.0180\n",
            "Epoch 2 / 10 | Step 390 / 985 | Loss = 0.0488\n",
            "Epoch 2 / 10 | Step 395 / 985 | Loss = 0.0534\n",
            "Epoch 2 / 10 | Step 400 / 985 | Loss = 0.0169\n",
            "Epoch 2 / 10 | Step 405 / 985 | Loss = 0.0179\n",
            "Epoch 2 / 10 | Step 410 / 985 | Loss = 0.1298\n",
            "Epoch 2 / 10 | Step 415 / 985 | Loss = 0.0490\n",
            "Epoch 2 / 10 | Step 420 / 985 | Loss = 0.0341\n",
            "Epoch 2 / 10 | Step 425 / 985 | Loss = 0.0372\n",
            "Epoch 2 / 10 | Step 430 / 985 | Loss = 0.0257\n",
            "Epoch 2 / 10 | Step 435 / 985 | Loss = 0.0493\n",
            "Epoch 2 / 10 | Step 440 / 985 | Loss = 0.0238\n",
            "Epoch 2 / 10 | Step 445 / 985 | Loss = 0.0217\n",
            "Epoch 2 / 10 | Step 450 / 985 | Loss = 0.0067\n",
            "Epoch 2 / 10 | Step 455 / 985 | Loss = 0.0010\n",
            "Epoch 2 / 10 | Step 460 / 985 | Loss = 0.0114\n",
            "Epoch 2 / 10 | Step 465 / 985 | Loss = 0.0211\n",
            "Epoch 2 / 10 | Step 470 / 985 | Loss = 0.0278\n",
            "Epoch 2 / 10 | Step 475 / 985 | Loss = 0.0470\n",
            "Epoch 2 / 10 | Step 480 / 985 | Loss = 0.0306\n",
            "Epoch 2 / 10 | Step 485 / 985 | Loss = 0.0349\n",
            "Epoch 2 / 10 | Step 490 / 985 | Loss = 0.0916\n",
            "Epoch 2 / 10 | Step 495 / 985 | Loss = 0.0949\n",
            "Epoch 2 / 10 | Step 500 / 985 | Loss = 0.0056\n",
            "Epoch 2 / 10 | Step 505 / 985 | Loss = 0.0107\n",
            "Epoch 2 / 10 | Step 510 / 985 | Loss = 0.0126\n",
            "Epoch 2 / 10 | Step 515 / 985 | Loss = 0.0709\n",
            "Epoch 2 / 10 | Step 520 / 985 | Loss = 0.0117\n",
            "Epoch 2 / 10 | Step 525 / 985 | Loss = 0.0211\n",
            "Epoch 2 / 10 | Step 530 / 985 | Loss = 0.0071\n",
            "Epoch 2 / 10 | Step 535 / 985 | Loss = 0.0142\n",
            "Epoch 2 / 10 | Step 540 / 985 | Loss = 0.0337\n",
            "Epoch 2 / 10 | Step 545 / 985 | Loss = 0.0572\n",
            "Epoch 2 / 10 | Step 550 / 985 | Loss = 0.0060\n",
            "Epoch 2 / 10 | Step 555 / 985 | Loss = 0.0589\n",
            "Epoch 2 / 10 | Step 560 / 985 | Loss = 0.0084\n",
            "Epoch 2 / 10 | Step 565 / 985 | Loss = 0.0106\n",
            "Epoch 2 / 10 | Step 570 / 985 | Loss = 0.0160\n",
            "Epoch 2 / 10 | Step 575 / 985 | Loss = 0.0900\n",
            "Epoch 2 / 10 | Step 580 / 985 | Loss = 0.0584\n",
            "Epoch 2 / 10 | Step 585 / 985 | Loss = 0.0071\n",
            "Epoch 2 / 10 | Step 590 / 985 | Loss = 0.0077\n",
            "Epoch 2 / 10 | Step 595 / 985 | Loss = 0.0259\n",
            "Epoch 2 / 10 | Step 600 / 985 | Loss = 0.0279\n",
            "Epoch 2 / 10 | Step 605 / 985 | Loss = 0.0229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "該算法接著在測試數據集上進行測試驗證。模型使用輸入特徵進行預測，並使用 torch.max 函數獲取預測的類別索引。處理完測試數據集中的所有批次後，計算模型的準確率。"
      ],
      "metadata": {
        "id": "HIZCIu_g9gJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    n_correct = 0\n",
        "    n_samples = 0\n",
        "    for features, labels in test_loader:\n",
        "        features = features.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(features)\n",
        "\n",
        "        # 獲取預測類別\n",
        "        _, predictions = torch.max(outputs, dim=1)\n",
        "        n_samples += labels.shape[0]\n",
        "        n_correct += (predictions == labels).sum().item()\n",
        "\n",
        "    acc = 100.0 * n_correct / n_samples\n",
        "    print(f'Accuracy = {acc:.2f}%')"
      ],
      "metadata": {
        "id": "QYJtVyGt9mBN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8308712-0c91-4515-9ab8-162a43d71186"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 1.36%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accuracy and Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "ichI0NBG9s8h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "我們的模型擁有94個輸入特徵、一個包含16個神經元的隱藏層和2個輸出神經元，在訓練10個周期後達到了88.5%的準確率。這表明我們的簡單模型未能適當捕捉數據集中的模式，特別是未能捕捉輸入特徵和輸出標籤之間的高度非線性關係。在此部分，我們將通過超參數調整來改進模型性能。增加模型參數數量會增加模型的容量，使神經網絡能更靈活地捕捉複雜的模式和依賴關係。我們將隱藏層的神經元數增加到64。"
      ],
      "metadata": {
        "id": "Aua71X-69yBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.l1 = nn.Linear(input_size, 64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(64, 64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.l3 = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.l3(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "QATJ2LnZ94v9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "在這種情況下，模型達到了90.3%的準確率，這比之前的準確率略有提升。這表明增加隱藏層中的神經元數量使模型能夠捕捉數據中的非線性關係。然而，進一步增加隱藏層神經元數量對模型的準確率影響不大。下一步是添加第二個隱藏層並微調每個隱藏層中的神經元數量。我們首先測試添加一個包含64個神經元的第二個隱藏層。"
      ],
      "metadata": {
        "id": "hVHhEYZF96Ln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.l1 = nn.Linear(input_size, 64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.l2 = nn.Linear(64, 64)\n",
        "        self.l3 = nn.Linear(64, 64)\n",
        "        self.l4 = nn.Linear(64, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.l3(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.l4(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "QViamPYm-H6L"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "模型的準確率在這個修改過的模型中保持在90.3%。此外，增加隱藏層的數量對模型性能沒有顯著影響。增加訓練周期也未能提升模型性能，這可能表明所用的損失函數優化器並不理想。\n",
        "\n",
        "我們改用流行的 Adam 優化器來訓練模型："
      ],
      "metadata": {
        "id": "oFpXlSPM-KXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 定義學習率\n",
        "learning_rate = 0.02\n",
        "\n",
        "# 損失函數和優化器\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "s7HLVXFj-McP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "使用 Adam 優化器後，單隱藏層模型的準確率提升到95%。調整多個超參數後，最佳準確率達到96.5%，使用了 Adam 優化器和0.02的學習率。"
      ],
      "metadata": {
        "id": "loHFwlxP-NrN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Used\n",
        "\n",
        "\n",
        "*   隨機森林分類器：因其穩健性和處理大數據集的能力而被使用。\n",
        "*   神經網絡：用於捕捉數據中的複雜模式。\n",
        "*   聯邦學習：增強隱私保護，分佈式訓練。\n",
        "\n"
      ],
      "metadata": {
        "id": "DhiIeyce6xWG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results\n",
        "\n",
        "\n",
        "*   準確率：95%\n",
        "*   召回率：94%\n",
        "*   F1 分數：93%\n",
        "*   潛在向量輸出：為進一步在 Orange 中分析而提取。\n",
        "\n"
      ],
      "metadata": {
        "id": "todny6m261YI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Orange Analysis\n"
      ],
      "metadata": {
        "id": "T3r44jms63ls"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iqqzPWw32Lp"
      },
      "outputs": [],
      "source": []
    }
  ]
}